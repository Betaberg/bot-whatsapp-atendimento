#!/usr/bin/env node

/**
 * Script para instalar e configurar o Ollama
 * Este script ajuda a configurar o Ollama para uso com o bot WhatsApp
 */

const { execSync, spawn } = require('child_process');
const fs = require('fs');
const path = require('path');

console.log('üîß Script de Instala√ß√£o do Ollama para Bot WhatsApp');
console.log('===============================================\n');

// Verificar se o sistema operacional √© Windows
const isWindows = process.platform === 'win32';

function checkOllamaInstalled() {
  try {
    execSync('ollama --version', { stdio: 'pipe' });
    return true;
  } catch (error) {
    return false;
  }
}

function installOllamaWindows() {
  console.log('üì• Baixando instalador do Ollama para Windows...');
  
  // Abrir p√°gina de download do Ollama
  try {
    if (isWindows) {
      execSync('start https://ollama.ai/download/OllamaSetup.exe', { stdio: 'ignore' });
    }
    console.log('‚úÖ Por favor, instale o Ollama usando o instalador baixado.');
    console.log('üîó URL: https://ollama.ai/download/OllamaSetup.exe\n');
  } catch (error) {
    console.log('‚ö†Ô∏è  N√£o foi poss√≠vel abrir o navegador automaticamente.');
    console.log('üîó Acesse manualmente: https://ollama.ai/download/OllamaSetup.exe\n');
  }
}

function installOllamaLinux() {
  console.log('üì• Instalando Ollama no Linux...');
  
  try {
    execSync('curl -fsSL https://ollama.ai/install.sh | sh', { stdio: 'inherit' });
    console.log('‚úÖ Ollama instalado com sucesso!\n');
  } catch (error) {
    console.log('‚ùå Erro ao instalar Ollama. Tente instalar manualmente:');
    console.log('   curl -fsSL https://ollama.ai/install.sh | sh\n');
  }
}

function startOllamaService() {
  console.log('üöÄ Iniciando servi√ßo Ollama...');
  
  try {
    if (isWindows) {
      // No Windows, o servi√ßo √© iniciado automaticamente ap√≥s a instala√ß√£o
      console.log('‚úÖ No Windows, o servi√ßo Ollama deve iniciar automaticamente.');
      console.log('üîß Se n√£o iniciar, execute: ollama serve\n');
    } else {
      // No Linux, iniciar o servi√ßo
      execSync('sudo systemctl start ollama', { stdio: 'inherit' });
      console.log('‚úÖ Servi√ßo Ollama iniciado!\n');
    }
  } catch (error) {
    console.log('‚ö†Ô∏è  N√£o foi poss√≠vel iniciar o servi√ßo Ollama automaticamente.');
    console.log('üîß Inicie manualmente com: ollama serve\n');
  }
}

function pullModel(modelName = 'llama3.2:3b') {
  console.log(`üì• Baixando modelo ${modelName}...`);
  
  try {
    execSync(`ollama pull ${modelName}`, { stdio: 'inherit' });
    console.log(`‚úÖ Modelo ${modelName} baixado com sucesso!\n`);
    return true;
  } catch (error) {
    console.log(`‚ùå Erro ao baixar modelo ${modelName}.`);
    console.log('üîß Tente baixar manualmente com: ollama pull llama3.2:3b\n');
    return false;
  }
}

function createEnvFile() {
  const envPath = path.join(__dirname, '..', '.env');
  const envContent = `# Bot Configuration
BOT_NUMBER=5569981248816
ROOT_NUMBERS=5569981170027,556884268042

# Database
DB_PATH=./db/atendimento.db

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b

# Logging
LOG_LEVEL=info

# Production Settings
NODE_ENV=production
PORT=3000
`;

  if (!fs.existsSync(envPath)) {
    fs.writeFileSync(envPath, envContent);
    console.log('‚úÖ Arquivo .env criado com configura√ß√µes padr√£o!\n');
  } else {
    console.log('‚ö†Ô∏è  Arquivo .env j√° existe. Verifique se as configura√ß√µes est√£o corretas.\n');
  }
}

function testOllamaConnection() {
  console.log('üß™ Testando conex√£o com Ollama...');
  
  try {
    const response = execSync('curl -s http://localhost:11434/api/tags', { encoding: 'utf8' });
    if (response) {
      console.log('‚úÖ Conex√£o com Ollama bem-sucedida!\n');
      return true;
    }
  } catch (error) {
    console.log('‚ùå N√£o foi poss√≠vel conectar ao Ollama.');
    console.log('üîß Verifique se o servi√ßo est√° rodando com: ollama serve\n');
  }
  
  return false;
}

async function main() {
  console.log('üîç Verificando instala√ß√£o do Ollama...');
  
  if (!checkOllamaInstalled()) {
    console.log('‚ùå Ollama n√£o est√° instalado.\n');
    
    if (isWindows) {
      installOllamaWindows();
    } else {
      installOllamaLinux();
    }
    
    console.log('üí° Ap√≥s instalar o Ollama, execute este script novamente.');
    return;
  }
  
  console.log('‚úÖ Ollama j√° est√° instalado!\n');
  
  // Criar arquivo .env se n√£o existir
  createEnvFile();
  
  // Iniciar servi√ßo Ollama
  startOllamaService();
  
  // Testar conex√£o
  if (!testOllamaConnection()) {
    console.log('üîß Iniciando servi√ßo Ollama...');
    const ollamaProcess = spawn('ollama', ['serve'], {
      stdio: 'ignore',
      detached: true
    });
    
    ollamaProcess.unref();
    
    // Aguardar um momento para o servi√ßo iniciar
    await new Promise(resolve => setTimeout(resolve, 3000));
    
    // Testar conex√£o novamente
    testOllamaConnection();
  }
  
  // Baixar modelo padr√£o
  console.log('üì• Verificando modelo padr√£o...');
  pullModel('llama3.2:3b');
  
  console.log('üéâ Configura√ß√£o conclu√≠da!');
  console.log('üöÄ Agora voc√™ pode iniciar o bot com: npm start\n');
}

if (require.main === module) {
  main().catch(error => {
    console.error('‚ùå Erro durante a instala√ß√£o:', error.message);
    process.exit(1);
  });
}

module.exports = {
  checkOllamaInstalled,
  installOllamaWindows,
  installOllamaLinux,
  startOllamaService,
  pullModel,
  createEnvFile,
  testOllamaConnection
};
