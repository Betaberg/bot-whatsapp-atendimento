# ğŸ¤– IntegraÃ§Ã£o com Ollama - Bot WhatsApp

## ğŸ“‹ VisÃ£o Geral

O bot foi atualizado para usar **Ollama** em vez do OpenAI, proporcionando uma soluÃ§Ã£o de IA local e gratuita para anÃ¡lise de mensagens e criaÃ§Ã£o de respostas inteligentes.

## ğŸš€ Funcionalidades da IA

### 1. **AnÃ¡lise Inteligente de Mensagens**
- **ClassificaÃ§Ã£o automÃ¡tica** de mensagens do usuÃ¡rio:
  - `SAUDACAO`: Cumprimentos e saudaÃ§Ãµes
  - `PROBLEMA`: DescriÃ§Ã£o de problemas tÃ©cnicos
  - `DUVIDA`: Perguntas sobre o sistema
  - `OUTRO`: Outras mensagens

### 2. **Primeira InteraÃ§Ã£o Personalizada**
- **Mensagem de boas-vindas** gerada pela IA
- **NÃ£o cria OS automaticamente** na primeira mensagem
- **OrientaÃ§Ã£o sobre uso** do sistema

### 3. **AnÃ¡lise de Problemas TÃ©cnicos**
- **CategorizaÃ§Ã£o automÃ¡tica** (Hardware, Software, Rede, etc.)
- **DefiniÃ§Ã£o de prioridade** (Alta, Normal, Baixa)
- **AnÃ¡lise breve** do problema reportado

## âš™ï¸ ConfiguraÃ§Ã£o do Ollama

### PrÃ©-requisitos
1. **Instalar Ollama**: https://ollama.ai/
2. **Baixar modelo recomendado**:
   ```bash
   ollama pull llama3.2:3b
   ```

### ConfiguraÃ§Ã£o no Bot
```javascript
// bot-whatsapp/config/config.js
ollama: {
  baseUrl: 'http://localhost:11434',  // URL do Ollama
  model: 'llama3.2:3b'                // Modelo a ser usado
}
```

### VariÃ¡veis de Ambiente (.env)
```env
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b
```

## ğŸ”„ Fluxo de InteraÃ§Ã£o Atualizado

### 1. **Primeira Mensagem do UsuÃ¡rio**
```
UsuÃ¡rio: "oi"
Bot: ğŸ‘‹ OlÃ¡! Sou seu assistente tÃ©cnico de TI.

ğŸ”§ Para abrir um chamado, descreva seu problema tÃ©cnico
ğŸ“‹ Use !ajuda para ver todos os comandos disponÃ­veis
ğŸ’¬ Estou aqui para ajudar com questÃµes de TI!
```

### 2. **Problema TÃ©cnico Identificado**
```
UsuÃ¡rio: "minha impressora nÃ£o estÃ¡ funcionando"
Bot: âœ… CHAMADO CRIADO COM SUCESSO

ğŸ« OS #123
ğŸ“ Problema: minha impressora nÃ£o estÃ¡ funcionando
ğŸ“… Criado em: 15/12/2024 14:30

ğŸ¤– AnÃ¡lise AutomÃ¡tica:
ğŸ“‚ Categoria: Impressora
âš¡ Prioridade: Normal
ğŸ” AnÃ¡lise: Problema comum de conectividade com impressora

ğŸ’¡ PrÃ³ximos passos:
â€¢ Use !dados para adicionar mais informaÃ§Ãµes
â€¢ Use !status 123 para consultar o andamento
â€¢ Nossa equipe tÃ©cnica foi notificada
```

### 3. **DÃºvidas sobre o Sistema**
```
UsuÃ¡rio: "como faÃ§o para abrir um chamado?"
Bot: â“ Entendi que vocÃª tem uma dÃºvida sobre o sistema.

ğŸ“‹ Use !ajuda para ver todos os comandos disponÃ­veis
ğŸ”§ Para abrir um chamado, descreva seu problema tÃ©cnico
ğŸ’¬ Posso ajudar com questÃµes de TI, impressoras, computadores, rede, etc.
```

## ğŸ› ï¸ Comandos TÃ©cnicos

### Para UsuÃ¡rios
- **Primeira mensagem**: Recebe boas-vindas personalizadas
- **Descrever problema**: Cria OS automaticamente com anÃ¡lise IA
- **!ajuda**: Lista de comandos disponÃ­veis
- **!status [id]**: Consultar status da OS
- **!dados**: Adicionar informaÃ§Ãµes detalhadas

### Para TÃ©cnicos (inalterados)
- **!list**: Listar OS abertas
- **!atendendo [id]**: Assumir OS
- **!finalizado [id]**: Finalizar OS
- **!listpeÃ§as [id]**: Solicitar peÃ§as

## ğŸ”§ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### 1. **Instalar Ollama**
```bash
# Linux/Mac
curl -fsSL https://ollama.ai/install.sh | sh

# Windows
# Baixar do site oficial: https://ollama.ai/
```

### 2. **Iniciar Ollama**
```bash
ollama serve
```

### 3. **Baixar Modelo**
```bash
ollama pull llama3.2:3b
```

### 4. **Verificar InstalaÃ§Ã£o**
```bash
ollama list
```

### 5. **Iniciar o Bot**
```bash
cd bot-whatsapp
npm install
npm start
```

## ğŸ“Š Monitoramento

### Status da ConexÃ£o Ollama
O bot verifica automaticamente a conexÃ£o com Ollama:
- âœ… **Conectado**: IA funcionando normalmente
- âš ï¸ **Desconectado**: Bot funciona sem IA (modo fallback)

### Logs
```
âœ… Ollama conectado com sucesso
âš ï¸ Ollama nÃ£o estÃ¡ disponÃ­vel
âš ï¸ Erro ao conectar com Ollama: Connection refused
```

## ğŸš¨ Troubleshooting

### Problema: Ollama nÃ£o conecta
**SoluÃ§Ã£o**:
1. Verificar se Ollama estÃ¡ rodando: `ollama serve`
2. Verificar URL no config: `http://localhost:11434`
3. Testar conexÃ£o: `curl http://localhost:11434/api/tags`

### Problema: Modelo nÃ£o encontrado
**SoluÃ§Ã£o**:
1. Listar modelos: `ollama list`
2. Baixar modelo: `ollama pull llama3.2:3b`
3. Verificar nome no config

### Problema: IA nÃ£o responde
**SoluÃ§Ã£o**:
1. Bot funciona em modo fallback (sem IA)
2. Verificar logs do Ollama
3. Reiniciar serviÃ§o Ollama

## ğŸ”„ Modelos Alternativos

### Modelos Recomendados
- **llama3.2:3b** (padrÃ£o) - RÃ¡pido e eficiente
- **llama3.2:1b** - Mais leve, menos preciso
- **mistral:7b** - Alternativa robusta
- **codellama:7b** - Especializado em cÃ³digo

### Trocar Modelo
```bash
# Baixar novo modelo
ollama pull mistral:7b

# Atualizar config
OLLAMA_MODEL=mistral:7b
```

## ğŸ“ˆ Performance

### Recursos Recomendados
- **RAM**: MÃ­nimo 8GB (16GB recomendado)
- **CPU**: 4+ cores
- **Armazenamento**: 10GB+ livre

### OtimizaÃ§Ã£o
- Usar modelos menores para melhor performance
- Configurar timeout adequado
- Monitorar uso de recursos

## ğŸ” SeguranÃ§a

### Vantagens do Ollama
- **Dados locais**: Nenhuma informaÃ§Ã£o enviada para terceiros
- **Privacidade**: Conversas permanecem no servidor
- **Controle total**: Sem dependÃªncia de APIs externas
- **Gratuito**: Sem custos de API

## ğŸ“ Logs e Debugging

### Logs da IA
```javascript
// Logs automÃ¡ticos no console
âœ… Ollama conectado com sucesso
ğŸ¤– AnÃ¡lise IA: PROBLEMA detectado
âš ï¸ Ollama nÃ£o disponÃ­vel, usando fallback
```

### Debug Manual
```javascript
// Testar conexÃ£o
const ollamaClient = require('./utils/ollama');
console.log(ollamaClient.getStatus());
```

## ğŸ¯ PrÃ³ximos Passos

1. **Monitoramento avanÃ§ado** de performance da IA
2. **Treinamento personalizado** com dados especÃ­ficos
3. **MÃºltiplos modelos** para diferentes tarefas
4. **Interface web** para configuraÃ§Ã£o da IA
5. **MÃ©tricas de precisÃ£o** da anÃ¡lise automÃ¡tica

---

**Nota**: O sistema funciona perfeitamente mesmo sem Ollama, mantendo todas as funcionalidades bÃ¡sicas do bot.
